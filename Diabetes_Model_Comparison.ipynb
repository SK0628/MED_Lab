{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba0e9b04",
   "metadata": {},
   "source": [
    "# Disease Prediction using SVM, Random Forest, and Gradient Boosting\n",
    "This notebook uses the Pima Indians Diabetes dataset to compare the performance of advanced supervised learning algorithms.\n",
    "- Dataset Source: OpenML `diabetes`\n",
    "- Target: Tested positive or negative for diabetes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90975ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.datasets import fetch_openml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011b1409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "data = fetch_openml(name='diabetes', version=1, as_frame=True)\n",
    "df = data.frame\n",
    "X = df.drop('class', axis=1)\n",
    "y = df['class'].apply(lambda x: 1 if x == 'tested_positive' else 0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690c2a00",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning & Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81af88d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM GridSearch\n",
    "param_grid_svm = {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf'], 'gamma': ['scale', 'auto']}\n",
    "grid_svm = GridSearchCV(SVC(probability=True), param_grid_svm, cv=5, scoring='roc_auc')\n",
    "grid_svm.fit(X_train, y_train)\n",
    "best_svm = grid_svm.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d977c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest GridSearch\n",
    "param_grid_rf = {'n_estimators': [100, 200], 'max_depth': [None, 10, 20]}\n",
    "grid_rf = GridSearchCV(RandomForestClassifier(), param_grid_rf, cv=5, scoring='roc_auc')\n",
    "grid_rf.fit(X_train, y_train)\n",
    "best_rf = grid_rf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed34ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Boosting GridSearch\n",
    "param_grid_gbm = {'n_estimators': [100, 200], 'learning_rate': [0.1, 0.05], 'max_depth': [3, 4]}\n",
    "grid_gbm = GridSearchCV(GradientBoostingClassifier(), param_grid_gbm, cv=5, scoring='roc_auc')\n",
    "grid_gbm.fit(X_train, y_train)\n",
    "best_gbm = grid_gbm.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4d6869",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c00dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model):\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_prob = model.predict_proba(X_test)[:, 1]\n",
    "    return {\n",
    "        'Accuracy': accuracy_score(y_test, y_pred),\n",
    "        'Precision': precision_score(y_test, y_pred),\n",
    "        'Recall': recall_score(y_test, y_pred),\n",
    "        'F1 Score': f1_score(y_test, y_pred),\n",
    "        'AUC-ROC': roc_auc_score(y_test, y_prob)\n",
    "    }\n",
    "\n",
    "results = {\n",
    "    'SVM': evaluate_model(best_svm),\n",
    "    'Random Forest': evaluate_model(best_rf),\n",
    "    'Gradient Boosting': evaluate_model(best_gbm)\n",
    "}\n",
    "results_df = pd.DataFrame(results).T\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563636d9",
   "metadata": {},
   "source": [
    "## Visualization of Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6e14f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.plot(kind='bar', figsize=(12, 6), title='Model Comparison')\n",
    "plt.ylabel('Score')\n",
    "plt.xticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
